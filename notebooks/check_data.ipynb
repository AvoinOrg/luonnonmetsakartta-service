{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from ftfy import fix_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = gpd.read_file(\"/app/data/test_data.zip\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fix encoding in a DataFrame column\n",
    "def fix_column_encoding(df, column):\n",
    "    if df[column].dtype == 'object':  # Only process string/object columns\n",
    "        df[column] = df[column].astype(str).apply(fix_text)\n",
    "    return df\n",
    "\n",
    "# Fix encoding in all string columns\n",
    "for column in test_data.columns:\n",
    "    if test_data[column].dtype == 'object':\n",
    "        test_data = fix_column_encoding(test_data, column)\n",
    "\n",
    "# Check a sample of the data to verify\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = gpd.read_file(\"/app/data/test_data.zip\")\n",
    "\n",
    "# Fix all string columns with the deep fix\n",
    "for column in test_data.columns:\n",
    "    if test_data[column].dtype == 'object':\n",
    "        test_data[column] = test_data[column].apply(deep_fix_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:3067 coordinates (ETRS89/TM35FIN):\n",
      "minx: 144286.33218675363\n",
      "maxx: 752934.2155768903\n",
      "miny: 6642928.395443255\n",
      "maxy: 7796732.440183549\n"
     ]
    }
   ],
   "source": [
    "from pyproj import Transformer\n",
    "\n",
    "# Define coordinates in EPSG:4326 (WGS84)\n",
    "wgs_coords = {\n",
    "    \"minx\": 20.6455928891,\n",
    "    \"maxx\": 31.5160921567,\n",
    "    \"miny\": 59.846373196,\n",
    "    \"maxy\": 70.1641930203,\n",
    "}\n",
    "\n",
    "# Create a transformer from EPSG:4326 to EPSG:3067\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:3067\", always_xy=True)\n",
    "\n",
    "# Transform each corner point\n",
    "sw = transformer.transform(wgs_coords[\"minx\"], wgs_coords[\"miny\"])\n",
    "se = transformer.transform(wgs_coords[\"maxx\"], wgs_coords[\"miny\"])\n",
    "ne = transformer.transform(wgs_coords[\"maxx\"], wgs_coords[\"maxy\"])\n",
    "nw = transformer.transform(wgs_coords[\"minx\"], wgs_coords[\"maxy\"])\n",
    "\n",
    "# Get the bounding box in ETRS89/TM35FIN coordinates\n",
    "etrs_coords = {\n",
    "    \"minx\": min(sw[0], nw[0]),\n",
    "    \"maxx\": max(se[0], ne[0]),\n",
    "    \"miny\": min(sw[1], se[1]),\n",
    "    \"maxy\": max(nw[1], ne[1]),\n",
    "}\n",
    "\n",
    "print(\"EPSG:3067 coordinates (ETRS89/TM35FIN):\")\n",
    "print(f\"minx: {etrs_coords['minx']}\")\n",
    "print(f\"maxx: {etrs_coords['maxx']}\")\n",
    "print(f\"miny: {etrs_coords['miny']}\")\n",
    "print(f\"maxy: {etrs_coords['maxy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved unique name+municipality shapefile to ../data/unique_name_mun.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/luonnonmetsakartta-service-9TtSrW0h-py3.12/lib/python3.12/site-packages/pyogrio/raw.py:723: RuntimeWarning: Value 'Ent. varuskunnan metsÃÆÃâÃâ Ã¢â¬â¢ÃÆÃ¢â¬Â ÃÂ¢Ã¢âÂ¬Ã¢âÂ¢ÃÆÃâÃÂ¢Ã¢âÂ¬ÃÂ ÃÆÃÂ¢ÃÂ¢Ã¢â¬Å¡ÃÂ¬ÃÂ¢Ã¢â¬Å¾ÃÂ¢ÃÆÃâÃâ Ã¢â¬â¢ÃÆÃÂ¢ÃÂ¢Ã¢â¬Å¡ÃÂ¬Ãâ¦ÃÂ¡ÃÆÃâÃÂ¢Ã¢âÂ¬ÃÂ¡ÃÆÃ¢â¬Å¡ÃâÃÂ¤t' of field nimi has been truncated to 254 characters.  This warning will not be emitted any more for that layer.\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "# Path to the original shapefile (update as needed)\n",
    "shp_path = Path('../data/test_data.zip')\n",
    "gdf = gpd.read_file(shp_path)\n",
    "\n",
    "# Columns for name and municipality (update as needed)\n",
    "name_col = 'nimi'\n",
    "mun_col = 'kunta'\n",
    "\n",
    "print(f\"Original data has {len(gdf)} features\")\n",
    "\n",
    "# Find all (name, municipality) combos that are unique\n",
    "combo_counts = gdf.groupby([name_col, mun_col]).size().reset_index(name='count')\n",
    "unique_combos = combo_counts[combo_counts['count'] == 1][[name_col, mun_col]]\n",
    "non_unique_combos = combo_counts[combo_counts['count'] > 1]\n",
    "\n",
    "print(f\"\\nFound {len(non_unique_combos)} non-unique name+municipality combinations:\")\n",
    "print(\"Name + Municipality combinations being removed (with count):\")\n",
    "for _, row in non_unique_combos.iterrows():\n",
    "    print(f\"  '{row[name_col]}' + '{row[mun_col]}': {row['count']} features\")\n",
    "\n",
    "# Merge to keep only unique combos\n",
    "gdf_unique = gdf.merge(unique_combos, on=[name_col, mun_col], how='inner')\n",
    "\n",
    "print(f\"\\nAfter removing duplicates: {len(gdf_unique)} features remaining\")\n",
    "print(f\"Removed {len(gdf) - len(gdf_unique)} features total\")\n",
    "\n",
    "# Save to a new shapefile\n",
    "out_dir = Path('../data/unique_name_mun')\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "out_shp = out_dir / 'unique_name_mun.shp'\n",
    "gdf_unique.to_file(out_shp)\n",
    "\n",
    "# Zip the shapefile\n",
    "zip_path = Path('../data/unique_name_mun.zip')\n",
    "with zipfile.ZipFile(zip_path, 'w') as zf:\n",
    "    for ext in ['.shp', '.shx', '.dbf', '.prj', '.cpg']:\n",
    "        f = out_shp.with_suffix(ext)\n",
    "        if f.exists():\n",
    "            zf.write(f, f.name)\n",
    "\n",
    "print(f\"\\nSaved unique name+municipality shapefile to {zip_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luonnonmetsakartta-service-9TtSrW0h-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
